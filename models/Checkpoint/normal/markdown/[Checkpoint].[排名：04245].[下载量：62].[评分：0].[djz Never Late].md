## djz Never Late
### 一、模型概述

- 标签：`style`, `late`, `never`, `djz`
- 下载数：62
- 收藏人数：8
- 评论人数：1
- 评分人数：0
- 评分：0

### 二、下载地址（共1个版本）

#### [版本1/共1个版本] v21

- 统计数据
  - 发布时间：2023-04-09T15:28:54.465Z
  - 原始模型：SD 2.1 768
  - 下载数：62
  - 评分人数：0
  - 评分：0
- 下载地址
  - [djzNeverLate_v21.safetensors](https://civitai.com/api/download/models/32818)
- 样例图像：

| <img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/76621a48-55c5-4201-2632-1250819ae000/width=450/374000.jpeg" /> | <img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/de7d6534-b93e-4b7e-a08a-413fef85d800/width=450/374008.jpeg" /> | <img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/7aa17067-47ce-4fe4-4a9f-2c4a9e5aef00/width=450/374007.jpeg" /> | <img src="https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA/10e0ed3b-4e56-4baa-bbc6-9be2c9fffa00/width=450/374006.jpeg" /> |
| ---- | ---- | ---- | ---- |


### 三、详情
<p>Demo images use <a target="_blank" rel="ugc" href="https://civitai.com/models/20517/danger-zoo-johnsons-negative-embeddings-helper-collection">Danger Zoo ~ Johnsons Negative TI Collection ~</a><br />Lora version: <a target="_blank" rel="ugc" href="https://civitai.com/models/19215/djz-never-late">djzNeverLate</a><br /><br />These "strong style" Models are intended to be merged with each other and any model for Stable Diffusion 2.1</p><p>I recommend merging with 0.5 (50/50 blend) then using prompt weighting to control the Aesthetic gradient.</p><p>example merged model prompt with automatic1111:</p><p><strong>(neverlate:1) (othermodeltoken:1)</strong></p><p>if you drop the "djz" and the "V21" what remains is the token you need to call up the concept in the model. All examples shown were the Raw Token, no other words. Tokens are case sensitive and in almost all models it will match the filename.</p><p>It is possible to merge these models with each other using a different value. It is possible to pair models and then merge those resulting models. In this way we can blend abstract concepts together and then weight the tokens to achieve the result we may wish to create. Of course to eliminate all those tokens, you can simply train a new custom model from the outputs, which means you are back to a single token.</p>